<!DOCTYPE html>
<!-- saved from url=(0014)about:internet -->
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
<meta http-equiv="x-ua-compatible" content="IE=9" >

<title>Prediction_Assignment_Writeup</title>

<style type="text/css">
body, td {
   font-family: sans-serif;
   background-color: white;
   font-size: 12px;
   margin: 8px;
}

tt, code, pre {
   font-family: 'DejaVu Sans Mono', 'Droid Sans Mono', 'Lucida Console', Consolas, Monaco, monospace;
}

h1 { 
   font-size:2.2em; 
}

h2 { 
   font-size:1.8em; 
}

h3 { 
   font-size:1.4em; 
}

h4 { 
   font-size:1.0em; 
}

h5 { 
   font-size:0.9em; 
}

h6 { 
   font-size:0.8em; 
}

a:visited {
   color: rgb(50%, 0%, 50%);
}

pre {	
   margin-top: 0;
   max-width: 95%;
   border: 1px solid #ccc;
   white-space: pre-wrap;
}

pre code {
   display: block; padding: 0.5em;
}

code.r, code.cpp {
   background-color: #F8F8F8;
}

table, td, th {
  border: none;
}

blockquote {
   color:#666666;
   margin:0;
   padding-left: 1em;
   border-left: 0.5em #EEE solid;
}

hr {
   height: 0px;
   border-bottom: none;
   border-top-width: thin;
   border-top-style: dotted;
   border-top-color: #999999;
}

@media print {
   * { 
      background: transparent !important; 
      color: black !important; 
      filter:none !important; 
      -ms-filter: none !important; 
   }

   body { 
      font-size:12pt; 
      max-width:100%; 
   }
       
   a, a:visited { 
      text-decoration: underline; 
   }

   hr { 
      visibility: hidden;
      page-break-before: always;
   }

   pre, blockquote { 
      padding-right: 1em; 
      page-break-inside: avoid; 
   }

   tr, img { 
      page-break-inside: avoid; 
   }

   img { 
      max-width: 100% !important; 
   }

   @page :left { 
      margin: 15mm 20mm 15mm 10mm; 
   }
     
   @page :right { 
      margin: 15mm 10mm 15mm 20mm; 
   }

   p, h2, h3 { 
      orphans: 3; widows: 3; 
   }

   h2, h3 { 
      page-break-after: avoid; 
   }
}

</style>

<!-- Styles for R syntax highlighter -->
<style type="text/css">
   pre .operator,
   pre .paren {
     color: rgb(104, 118, 135)
   }

   pre .literal {
     color: rgb(88, 72, 246)
   }

   pre .number {
     color: rgb(0, 0, 205);
   }

   pre .comment {
     color: rgb(76, 136, 107);
   }

   pre .keyword {
     color: rgb(0, 0, 255);
   }

   pre .identifier {
     color: rgb(0, 0, 0);
   }

   pre .string {
     color: rgb(3, 106, 7);
   }
</style>

<!-- R syntax highlighter -->
<script type="text/javascript">
var hljs=new function(){function m(p){return p.replace(/&/gm,"&amp;").replace(/</gm,"&lt;")}function f(r,q,p){return RegExp(q,"m"+(r.cI?"i":"")+(p?"g":""))}function b(r){for(var p=0;p<r.childNodes.length;p++){var q=r.childNodes[p];if(q.nodeName=="CODE"){return q}if(!(q.nodeType==3&&q.nodeValue.match(/\s+/))){break}}}function h(t,s){var p="";for(var r=0;r<t.childNodes.length;r++){if(t.childNodes[r].nodeType==3){var q=t.childNodes[r].nodeValue;if(s){q=q.replace(/\n/g,"")}p+=q}else{if(t.childNodes[r].nodeName=="BR"){p+="\n"}else{p+=h(t.childNodes[r])}}}if(/MSIE [678]/.test(navigator.userAgent)){p=p.replace(/\r/g,"\n")}return p}function a(s){var r=s.className.split(/\s+/);r=r.concat(s.parentNode.className.split(/\s+/));for(var q=0;q<r.length;q++){var p=r[q].replace(/^language-/,"");if(e[p]){return p}}}function c(q){var p=[];(function(s,t){for(var r=0;r<s.childNodes.length;r++){if(s.childNodes[r].nodeType==3){t+=s.childNodes[r].nodeValue.length}else{if(s.childNodes[r].nodeName=="BR"){t+=1}else{if(s.childNodes[r].nodeType==1){p.push({event:"start",offset:t,node:s.childNodes[r]});t=arguments.callee(s.childNodes[r],t);p.push({event:"stop",offset:t,node:s.childNodes[r]})}}}}return t})(q,0);return p}function k(y,w,x){var q=0;var z="";var s=[];function u(){if(y.length&&w.length){if(y[0].offset!=w[0].offset){return(y[0].offset<w[0].offset)?y:w}else{return w[0].event=="start"?y:w}}else{return y.length?y:w}}function t(D){var A="<"+D.nodeName.toLowerCase();for(var B=0;B<D.attributes.length;B++){var C=D.attributes[B];A+=" "+C.nodeName.toLowerCase();if(C.value!==undefined&&C.value!==false&&C.value!==null){A+='="'+m(C.value)+'"'}}return A+">"}while(y.length||w.length){var v=u().splice(0,1)[0];z+=m(x.substr(q,v.offset-q));q=v.offset;if(v.event=="start"){z+=t(v.node);s.push(v.node)}else{if(v.event=="stop"){var p,r=s.length;do{r--;p=s[r];z+=("</"+p.nodeName.toLowerCase()+">")}while(p!=v.node);s.splice(r,1);while(r<s.length){z+=t(s[r]);r++}}}}return z+m(x.substr(q))}function j(){function q(x,y,v){if(x.compiled){return}var u;var s=[];if(x.k){x.lR=f(y,x.l||hljs.IR,true);for(var w in x.k){if(!x.k.hasOwnProperty(w)){continue}if(x.k[w] instanceof Object){u=x.k[w]}else{u=x.k;w="keyword"}for(var r in u){if(!u.hasOwnProperty(r)){continue}x.k[r]=[w,u[r]];s.push(r)}}}if(!v){if(x.bWK){x.b="\\b("+s.join("|")+")\\s"}x.bR=f(y,x.b?x.b:"\\B|\\b");if(!x.e&&!x.eW){x.e="\\B|\\b"}if(x.e){x.eR=f(y,x.e)}}if(x.i){x.iR=f(y,x.i)}if(x.r===undefined){x.r=1}if(!x.c){x.c=[]}x.compiled=true;for(var t=0;t<x.c.length;t++){if(x.c[t]=="self"){x.c[t]=x}q(x.c[t],y,false)}if(x.starts){q(x.starts,y,false)}}for(var p in e){if(!e.hasOwnProperty(p)){continue}q(e[p].dM,e[p],true)}}function d(B,C){if(!j.called){j();j.called=true}function q(r,M){for(var L=0;L<M.c.length;L++){if((M.c[L].bR.exec(r)||[null])[0]==r){return M.c[L]}}}function v(L,r){if(D[L].e&&D[L].eR.test(r)){return 1}if(D[L].eW){var M=v(L-1,r);return M?M+1:0}return 0}function w(r,L){return L.i&&L.iR.test(r)}function K(N,O){var M=[];for(var L=0;L<N.c.length;L++){M.push(N.c[L].b)}var r=D.length-1;do{if(D[r].e){M.push(D[r].e)}r--}while(D[r+1].eW);if(N.i){M.push(N.i)}return f(O,M.join("|"),true)}function p(M,L){var N=D[D.length-1];if(!N.t){N.t=K(N,E)}N.t.lastIndex=L;var r=N.t.exec(M);return r?[M.substr(L,r.index-L),r[0],false]:[M.substr(L),"",true]}function z(N,r){var L=E.cI?r[0].toLowerCase():r[0];var M=N.k[L];if(M&&M instanceof Array){return M}return false}function F(L,P){L=m(L);if(!P.k){return L}var r="";var O=0;P.lR.lastIndex=0;var M=P.lR.exec(L);while(M){r+=L.substr(O,M.index-O);var N=z(P,M);if(N){x+=N[1];r+='<span class="'+N[0]+'">'+M[0]+"</span>"}else{r+=M[0]}O=P.lR.lastIndex;M=P.lR.exec(L)}return r+L.substr(O,L.length-O)}function J(L,M){if(M.sL&&e[M.sL]){var r=d(M.sL,L);x+=r.keyword_count;return r.value}else{return F(L,M)}}function I(M,r){var L=M.cN?'<span class="'+M.cN+'">':"";if(M.rB){y+=L;M.buffer=""}else{if(M.eB){y+=m(r)+L;M.buffer=""}else{y+=L;M.buffer=r}}D.push(M);A+=M.r}function G(N,M,Q){var R=D[D.length-1];if(Q){y+=J(R.buffer+N,R);return false}var P=q(M,R);if(P){y+=J(R.buffer+N,R);I(P,M);return P.rB}var L=v(D.length-1,M);if(L){var O=R.cN?"</span>":"";if(R.rE){y+=J(R.buffer+N,R)+O}else{if(R.eE){y+=J(R.buffer+N,R)+O+m(M)}else{y+=J(R.buffer+N+M,R)+O}}while(L>1){O=D[D.length-2].cN?"</span>":"";y+=O;L--;D.length--}var r=D[D.length-1];D.length--;D[D.length-1].buffer="";if(r.starts){I(r.starts,"")}return R.rE}if(w(M,R)){throw"Illegal"}}var E=e[B];var D=[E.dM];var A=0;var x=0;var y="";try{var s,u=0;E.dM.buffer="";do{s=p(C,u);var t=G(s[0],s[1],s[2]);u+=s[0].length;if(!t){u+=s[1].length}}while(!s[2]);if(D.length>1){throw"Illegal"}return{r:A,keyword_count:x,value:y}}catch(H){if(H=="Illegal"){return{r:0,keyword_count:0,value:m(C)}}else{throw H}}}function g(t){var p={keyword_count:0,r:0,value:m(t)};var r=p;for(var q in e){if(!e.hasOwnProperty(q)){continue}var s=d(q,t);s.language=q;if(s.keyword_count+s.r>r.keyword_count+r.r){r=s}if(s.keyword_count+s.r>p.keyword_count+p.r){r=p;p=s}}if(r.language){p.second_best=r}return p}function i(r,q,p){if(q){r=r.replace(/^((<[^>]+>|\t)+)/gm,function(t,w,v,u){return w.replace(/\t/g,q)})}if(p){r=r.replace(/\n/g,"<br>")}return r}function n(t,w,r){var x=h(t,r);var v=a(t);var y,s;if(v){y=d(v,x)}else{return}var q=c(t);if(q.length){s=document.createElement("pre");s.innerHTML=y.value;y.value=k(q,c(s),x)}y.value=i(y.value,w,r);var u=t.className;if(!u.match("(\\s|^)(language-)?"+v+"(\\s|$)")){u=u?(u+" "+v):v}if(/MSIE [678]/.test(navigator.userAgent)&&t.tagName=="CODE"&&t.parentNode.tagName=="PRE"){s=t.parentNode;var p=document.createElement("div");p.innerHTML="<pre><code>"+y.value+"</code></pre>";t=p.firstChild.firstChild;p.firstChild.cN=s.cN;s.parentNode.replaceChild(p.firstChild,s)}else{t.innerHTML=y.value}t.className=u;t.result={language:v,kw:y.keyword_count,re:y.r};if(y.second_best){t.second_best={language:y.second_best.language,kw:y.second_best.keyword_count,re:y.second_best.r}}}function o(){if(o.called){return}o.called=true;var r=document.getElementsByTagName("pre");for(var p=0;p<r.length;p++){var q=b(r[p]);if(q){n(q,hljs.tabReplace)}}}function l(){if(window.addEventListener){window.addEventListener("DOMContentLoaded",o,false);window.addEventListener("load",o,false)}else{if(window.attachEvent){window.attachEvent("onload",o)}else{window.onload=o}}}var e={};this.LANGUAGES=e;this.highlight=d;this.highlightAuto=g;this.fixMarkup=i;this.highlightBlock=n;this.initHighlighting=o;this.initHighlightingOnLoad=l;this.IR="[a-zA-Z][a-zA-Z0-9_]*";this.UIR="[a-zA-Z_][a-zA-Z0-9_]*";this.NR="\\b\\d+(\\.\\d+)?";this.CNR="\\b(0[xX][a-fA-F0-9]+|(\\d+(\\.\\d*)?|\\.\\d+)([eE][-+]?\\d+)?)";this.BNR="\\b(0b[01]+)";this.RSR="!|!=|!==|%|%=|&|&&|&=|\\*|\\*=|\\+|\\+=|,|\\.|-|-=|/|/=|:|;|<|<<|<<=|<=|=|==|===|>|>=|>>|>>=|>>>|>>>=|\\?|\\[|\\{|\\(|\\^|\\^=|\\||\\|=|\\|\\||~";this.ER="(?![\\s\\S])";this.BE={b:"\\\\.",r:0};this.ASM={cN:"string",b:"'",e:"'",i:"\\n",c:[this.BE],r:0};this.QSM={cN:"string",b:'"',e:'"',i:"\\n",c:[this.BE],r:0};this.CLCM={cN:"comment",b:"//",e:"$"};this.CBLCLM={cN:"comment",b:"/\\*",e:"\\*/"};this.HCM={cN:"comment",b:"#",e:"$"};this.NM={cN:"number",b:this.NR,r:0};this.CNM={cN:"number",b:this.CNR,r:0};this.BNM={cN:"number",b:this.BNR,r:0};this.inherit=function(r,s){var p={};for(var q in r){p[q]=r[q]}if(s){for(var q in s){p[q]=s[q]}}return p}}();hljs.LANGUAGES.cpp=function(){var a={keyword:{"false":1,"int":1,"float":1,"while":1,"private":1,"char":1,"catch":1,"export":1,virtual:1,operator:2,sizeof:2,dynamic_cast:2,typedef:2,const_cast:2,"const":1,struct:1,"for":1,static_cast:2,union:1,namespace:1,unsigned:1,"long":1,"throw":1,"volatile":2,"static":1,"protected":1,bool:1,template:1,mutable:1,"if":1,"public":1,friend:2,"do":1,"return":1,"goto":1,auto:1,"void":2,"enum":1,"else":1,"break":1,"new":1,extern:1,using:1,"true":1,"class":1,asm:1,"case":1,typeid:1,"short":1,reinterpret_cast:2,"default":1,"double":1,register:1,explicit:1,signed:1,typename:1,"try":1,"this":1,"switch":1,"continue":1,wchar_t:1,inline:1,"delete":1,alignof:1,char16_t:1,char32_t:1,constexpr:1,decltype:1,noexcept:1,nullptr:1,static_assert:1,thread_local:1,restrict:1,_Bool:1,complex:1},built_in:{std:1,string:1,cin:1,cout:1,cerr:1,clog:1,stringstream:1,istringstream:1,ostringstream:1,auto_ptr:1,deque:1,list:1,queue:1,stack:1,vector:1,map:1,set:1,bitset:1,multiset:1,multimap:1,unordered_set:1,unordered_map:1,unordered_multiset:1,unordered_multimap:1,array:1,shared_ptr:1}};return{dM:{k:a,i:"</",c:[hljs.CLCM,hljs.CBLCLM,hljs.QSM,{cN:"string",b:"'\\\\?.",e:"'",i:"."},{cN:"number",b:"\\b(\\d+(\\.\\d*)?|\\.\\d+)(u|U|l|L|ul|UL|f|F)"},hljs.CNM,{cN:"preprocessor",b:"#",e:"$"},{cN:"stl_container",b:"\\b(deque|list|queue|stack|vector|map|set|bitset|multiset|multimap|unordered_map|unordered_set|unordered_multiset|unordered_multimap|array)\\s*<",e:">",k:a,r:10,c:["self"]}]}}}();hljs.LANGUAGES.r={dM:{c:[hljs.HCM,{cN:"number",b:"\\b0[xX][0-9a-fA-F]+[Li]?\\b",e:hljs.IMMEDIATE_RE,r:0},{cN:"number",b:"\\b\\d+(?:[eE][+\\-]?\\d*)?L\\b",e:hljs.IMMEDIATE_RE,r:0},{cN:"number",b:"\\b\\d+\\.(?!\\d)(?:i\\b)?",e:hljs.IMMEDIATE_RE,r:1},{cN:"number",b:"\\b\\d+(?:\\.\\d*)?(?:[eE][+\\-]?\\d*)?i?\\b",e:hljs.IMMEDIATE_RE,r:0},{cN:"number",b:"\\.\\d+(?:[eE][+\\-]?\\d*)?i?\\b",e:hljs.IMMEDIATE_RE,r:1},{cN:"keyword",b:"(?:tryCatch|library|setGeneric|setGroupGeneric)\\b",e:hljs.IMMEDIATE_RE,r:10},{cN:"keyword",b:"\\.\\.\\.",e:hljs.IMMEDIATE_RE,r:10},{cN:"keyword",b:"\\.\\.\\d+(?![\\w.])",e:hljs.IMMEDIATE_RE,r:10},{cN:"keyword",b:"\\b(?:function)",e:hljs.IMMEDIATE_RE,r:2},{cN:"keyword",b:"(?:if|in|break|next|repeat|else|for|return|switch|while|try|stop|warning|require|attach|detach|source|setMethod|setClass)\\b",e:hljs.IMMEDIATE_RE,r:1},{cN:"literal",b:"(?:NA|NA_integer_|NA_real_|NA_character_|NA_complex_)\\b",e:hljs.IMMEDIATE_RE,r:10},{cN:"literal",b:"(?:NULL|TRUE|FALSE|T|F|Inf|NaN)\\b",e:hljs.IMMEDIATE_RE,r:1},{cN:"identifier",b:"[a-zA-Z.][a-zA-Z0-9._]*\\b",e:hljs.IMMEDIATE_RE,r:0},{cN:"operator",b:"<\\-(?!\\s*\\d)",e:hljs.IMMEDIATE_RE,r:2},{cN:"operator",b:"\\->|<\\-",e:hljs.IMMEDIATE_RE,r:1},{cN:"operator",b:"%%|~",e:hljs.IMMEDIATE_RE},{cN:"operator",b:">=|<=|==|!=|\\|\\||&&|=|\\+|\\-|\\*|/|\\^|>|<|!|&|\\||\\$|:",e:hljs.IMMEDIATE_RE,r:0},{cN:"operator",b:"%",e:"%",i:"\\n",r:1},{cN:"identifier",b:"`",e:"`",r:0},{cN:"string",b:'"',e:'"',c:[hljs.BE],r:0},{cN:"string",b:"'",e:"'",c:[hljs.BE],r:0},{cN:"paren",b:"[[({\\])}]",e:hljs.IMMEDIATE_RE,r:0}]}};
hljs.initHighlightingOnLoad();
</script>




</head>

<body>
<h2>Prediction_Assignment_Writeup</h2>

<h2>Executive summary </h2>

<p>Outlined below I used personal activity data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. These participants were asked to perform barbell lifts correctly and incorrectly in 5 different ways. I took this data and constructed a machine learning algorithm that allowed me to predict accurately the manner in which they exercised. Ultimately the random forest approach proved to be the best being able accurately predict all 20 entries in my test data set.</p>

<p>More information on this study can be found here: <a href="http://groupware.les.inf.puc-rio.br/har">http://groupware.les.inf.puc-rio.br/har</a></p>

<h2>Load libraries and results Function</h2>

<p>Session info</p>

<pre><code class="r">sessionInfo()
</code></pre>

<pre><code>## R version 3.1.0 (2014-04-10)
## Platform: x86_64-w64-mingw32/x64 (64-bit)
## 
## locale:
## [1] LC_COLLATE=English_United States.1252 
## [2] LC_CTYPE=English_United States.1252   
## [3] LC_MONETARY=English_United States.1252
## [4] LC_NUMERIC=C                          
## [5] LC_TIME=English_United States.1252    
## 
## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
## [1] knitr_1.8
## 
## loaded via a namespace (and not attached):
## [1] evaluate_0.5.5 formatR_1.0    stringr_0.6.2  tools_3.1.0
</code></pre>

<pre><code class="r">library(caret)
</code></pre>

<pre><code>## Warning: package &#39;caret&#39; was built under R version 3.1.2
</code></pre>

<pre><code>## Loading required package: lattice
## Loading required package: ggplot2
</code></pre>

<pre><code>## Warning: package &#39;ggplot2&#39; was built under R version 3.1.2
</code></pre>

<pre><code class="r">library(randomForest)
</code></pre>

<pre><code>## Warning: package &#39;randomForest&#39; was built under R version 3.1.2
</code></pre>

<pre><code>## randomForest 4.6-10
## Type rfNews() to see new features/changes/bug fixes.
</code></pre>

<pre><code class="r">library(RCurl)
</code></pre>

<pre><code>## Warning: package &#39;RCurl&#39; was built under R version 3.1.2
</code></pre>

<pre><code>## Loading required package: bitops
</code></pre>

<pre><code class="r">library(e1071)
</code></pre>

<pre><code>## Warning: package &#39;e1071&#39; was built under R version 3.1.2
</code></pre>

<pre><code class="r">library(rattle)
</code></pre>

<pre><code>## Warning: package &#39;rattle&#39; was built under R version 3.1.2
</code></pre>

<pre><code>## Rattle: A free graphical interface for data mining with R.
## Version 3.4.1 Copyright (c) 2006-2014 Togaware Pty Ltd.
## Type &#39;rattle()&#39; to shake, rattle, and roll your data.
</code></pre>

<pre><code class="r">library(WGCNA)
</code></pre>

<pre><code>## Warning: package &#39;WGCNA&#39; was built under R version 3.1.2
</code></pre>

<pre><code>## Loading required package: dynamicTreeCut
</code></pre>

<pre><code>## Warning: package &#39;dynamicTreeCut&#39; was built under R version 3.1.2
</code></pre>

<pre><code>## Loading required package: fastcluster
</code></pre>

<pre><code>## Warning: package &#39;fastcluster&#39; was built under R version 3.1.2
</code></pre>

<pre><code>## 
## Attaching package: &#39;fastcluster&#39;
## 
## The following object is masked from &#39;package:stats&#39;:
## 
##     hclust
</code></pre>

<pre><code>## Warning: package &#39;RSQLite&#39; was built under R version 3.1.2
</code></pre>

<pre><code>## Loading required package: DBI
</code></pre>

<pre><code>## Warning: package &#39;DBI&#39; was built under R version 3.1.2
</code></pre>

<pre><code>## Loading required package: AnnotationDbi
</code></pre>

<pre><code>## Warning: package &#39;AnnotationDbi&#39; was built under R version 3.1.1
</code></pre>

<pre><code>## Loading required package: BiocGenerics
## Loading required package: parallel
## 
## Attaching package: &#39;BiocGenerics&#39;
## 
## The following objects are masked from &#39;package:parallel&#39;:
## 
##     clusterApply, clusterApplyLB, clusterCall, clusterEvalQ,
##     clusterExport, clusterMap, parApply, parCapply, parLapply,
##     parLapplyLB, parRapply, parSapply, parSapplyLB
## 
## The following object is masked from &#39;package:randomForest&#39;:
## 
##     combine
## 
## The following object is masked from &#39;package:stats&#39;:
## 
##     xtabs
## 
## The following objects are masked from &#39;package:base&#39;:
## 
##     anyDuplicated, append, as.data.frame, as.vector, cbind,
##     colnames, do.call, duplicated, eval, evalq, Filter, Find, get,
##     intersect, is.unsorted, lapply, Map, mapply, match, mget,
##     order, paste, pmax, pmax.int, pmin, pmin.int, Position, rank,
##     rbind, Reduce, rep.int, rownames, sapply, setdiff, sort,
##     table, tapply, union, unique, unlist
## 
## Loading required package: Biobase
## Welcome to Bioconductor
## 
##     Vignettes contain introductory material; view with
##     &#39;browseVignettes()&#39;. To cite Bioconductor, see
##     &#39;citation(&quot;Biobase&quot;)&#39;, and for packages &#39;citation(&quot;pkgname&quot;)&#39;.
## 
## Loading required package: GenomeInfoDb
</code></pre>

<pre><code>## ==========================================================================
## *
## *  Package WGCNA 1.43 loaded.
## *
## *    Important note: It appears that your system supports multi-threading,
## *    but it is not enabled within WGCNA in R. 
## *    To allow multi-threading within WGCNA with all available cores, use 
## *
## *          allowWGCNAThreads()
## *
## *    within R. Use disableWGCNAThreads() to disable threading if necessary.
## *    Alternatively, set the following environment variable on your system:
## *
## *          ALLOW_WGCNA_THREADS=&lt;number_of_processors&gt;
## *
## *    for example 
## *
## *          ALLOW_WGCNA_THREADS=4
## *
## *    To set the environment variable in linux bash shell, type 
## *
## *           export ALLOW_WGCNA_THREADS=4
## *
## *     before running R. Other operating systems or shells will
## *     have a similar command to achieve the same aim.
## *
## ==========================================================================
</code></pre>

<pre><code>## 
## Attaching package: &#39;WGCNA&#39;
## 
## The following object is masked from &#39;package:stats&#39;:
## 
##     cor
</code></pre>

<pre><code class="r">pml_write_files = function(x){
  n = length(x)
  for(i in 1:n){
    filename = paste0(&quot;problem_id_&quot;,i,&quot;.txt&quot;)
    write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
  }
}
</code></pre>

<p>Setting a seed and loading in our data</p>

<pre><code class="r">set.seed(1234)

PML_training &lt;- read.csv(file=&quot;C:\\coursera\\ML\\pml-training.csv&quot;, header=T)

PML_testing &lt;- read.csv(file=&quot;C:\\coursera\\ML\\pml-testing.csv&quot;, header=T)
</code></pre>

<p>Data Preprocessing and Cleaning</p>

<pre><code class="r">#Now lets take a look at the data

str(PML_training)
</code></pre>

<pre><code>## &#39;data.frame&#39;:    19622 obs. of  160 variables:
##  $ X                       : int  1 2 3 4 5 6 7 8 9 10 ...
##  $ user_name               : Factor w/ 6 levels &quot;adelmo&quot;,&quot;carlitos&quot;,..: 2 2 2 2 2 2 2 2 2 2 ...
##  $ raw_timestamp_part_1    : int  1323084231 1323084231 1323084231 1323084232 1323084232 1323084232 1323084232 1323084232 1323084232 1323084232 ...
##  $ raw_timestamp_part_2    : int  788290 808298 820366 120339 196328 304277 368296 440390 484323 484434 ...
##  $ cvtd_timestamp          : Factor w/ 20 levels &quot;02/12/2011 13:32&quot;,..: 9 9 9 9 9 9 9 9 9 9 ...
##  $ new_window              : Factor w/ 2 levels &quot;no&quot;,&quot;yes&quot;: 1 1 1 1 1 1 1 1 1 1 ...
##  $ num_window              : int  11 11 11 12 12 12 12 12 12 12 ...
##  $ roll_belt               : num  1.41 1.41 1.42 1.48 1.48 1.45 1.42 1.42 1.43 1.45 ...
##  $ pitch_belt              : num  8.07 8.07 8.07 8.05 8.07 8.06 8.09 8.13 8.16 8.17 ...
##  $ yaw_belt                : num  -94.4 -94.4 -94.4 -94.4 -94.4 -94.4 -94.4 -94.4 -94.4 -94.4 ...
##  $ total_accel_belt        : int  3 3 3 3 3 3 3 3 3 3 ...
##  $ kurtosis_roll_belt      : Factor w/ 397 levels &quot;&quot;,&quot;-0.016850&quot;,..: 1 1 1 1 1 1 1 1 1 1 ...
##  $ kurtosis_picth_belt     : Factor w/ 317 levels &quot;&quot;,&quot;-0.021887&quot;,..: 1 1 1 1 1 1 1 1 1 1 ...
##  $ kurtosis_yaw_belt       : Factor w/ 2 levels &quot;&quot;,&quot;#DIV/0!&quot;: 1 1 1 1 1 1 1 1 1 1 ...
##  $ skewness_roll_belt      : Factor w/ 395 levels &quot;&quot;,&quot;-0.003095&quot;,..: 1 1 1 1 1 1 1 1 1 1 ...
##  $ skewness_roll_belt.1    : Factor w/ 338 levels &quot;&quot;,&quot;-0.005928&quot;,..: 1 1 1 1 1 1 1 1 1 1 ...
##  $ skewness_yaw_belt       : Factor w/ 2 levels &quot;&quot;,&quot;#DIV/0!&quot;: 1 1 1 1 1 1 1 1 1 1 ...
##  $ max_roll_belt           : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ max_picth_belt          : int  NA NA NA NA NA NA NA NA NA NA ...
##  $ max_yaw_belt            : Factor w/ 68 levels &quot;&quot;,&quot;-0.1&quot;,&quot;-0.2&quot;,..: 1 1 1 1 1 1 1 1 1 1 ...
##  $ min_roll_belt           : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ min_pitch_belt          : int  NA NA NA NA NA NA NA NA NA NA ...
##  $ min_yaw_belt            : Factor w/ 68 levels &quot;&quot;,&quot;-0.1&quot;,&quot;-0.2&quot;,..: 1 1 1 1 1 1 1 1 1 1 ...
##  $ amplitude_roll_belt     : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ amplitude_pitch_belt    : int  NA NA NA NA NA NA NA NA NA NA ...
##  $ amplitude_yaw_belt      : Factor w/ 4 levels &quot;&quot;,&quot;#DIV/0!&quot;,&quot;0.00&quot;,..: 1 1 1 1 1 1 1 1 1 1 ...
##  $ var_total_accel_belt    : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ avg_roll_belt           : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ stddev_roll_belt        : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ var_roll_belt           : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ avg_pitch_belt          : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ stddev_pitch_belt       : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ var_pitch_belt          : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ avg_yaw_belt            : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ stddev_yaw_belt         : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ var_yaw_belt            : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ gyros_belt_x            : num  0 0.02 0 0.02 0.02 0.02 0.02 0.02 0.02 0.03 ...
##  $ gyros_belt_y            : num  0 0 0 0 0.02 0 0 0 0 0 ...
##  $ gyros_belt_z            : num  -0.02 -0.02 -0.02 -0.03 -0.02 -0.02 -0.02 -0.02 -0.02 0 ...
##  $ accel_belt_x            : int  -21 -22 -20 -22 -21 -21 -22 -22 -20 -21 ...
##  $ accel_belt_y            : int  4 4 5 3 2 4 3 4 2 4 ...
##  $ accel_belt_z            : int  22 22 23 21 24 21 21 21 24 22 ...
##  $ magnet_belt_x           : int  -3 -7 -2 -6 -6 0 -4 -2 1 -3 ...
##  $ magnet_belt_y           : int  599 608 600 604 600 603 599 603 602 609 ...
##  $ magnet_belt_z           : int  -313 -311 -305 -310 -302 -312 -311 -313 -312 -308 ...
##  $ roll_arm                : num  -128 -128 -128 -128 -128 -128 -128 -128 -128 -128 ...
##  $ pitch_arm               : num  22.5 22.5 22.5 22.1 22.1 22 21.9 21.8 21.7 21.6 ...
##  $ yaw_arm                 : num  -161 -161 -161 -161 -161 -161 -161 -161 -161 -161 ...
##  $ total_accel_arm         : int  34 34 34 34 34 34 34 34 34 34 ...
##  $ var_accel_arm           : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ avg_roll_arm            : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ stddev_roll_arm         : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ var_roll_arm            : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ avg_pitch_arm           : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ stddev_pitch_arm        : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ var_pitch_arm           : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ avg_yaw_arm             : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ stddev_yaw_arm          : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ var_yaw_arm             : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ gyros_arm_x             : num  0 0.02 0.02 0.02 0 0.02 0 0.02 0.02 0.02 ...
##  $ gyros_arm_y             : num  0 -0.02 -0.02 -0.03 -0.03 -0.03 -0.03 -0.02 -0.03 -0.03 ...
##  $ gyros_arm_z             : num  -0.02 -0.02 -0.02 0.02 0 0 0 0 -0.02 -0.02 ...
##  $ accel_arm_x             : int  -288 -290 -289 -289 -289 -289 -289 -289 -288 -288 ...
##  $ accel_arm_y             : int  109 110 110 111 111 111 111 111 109 110 ...
##  $ accel_arm_z             : int  -123 -125 -126 -123 -123 -122 -125 -124 -122 -124 ...
##  $ magnet_arm_x            : int  -368 -369 -368 -372 -374 -369 -373 -372 -369 -376 ...
##  $ magnet_arm_y            : int  337 337 344 344 337 342 336 338 341 334 ...
##  $ magnet_arm_z            : int  516 513 513 512 506 513 509 510 518 516 ...
##  $ kurtosis_roll_arm       : Factor w/ 330 levels &quot;&quot;,&quot;-0.02438&quot;,..: 1 1 1 1 1 1 1 1 1 1 ...
##  $ kurtosis_picth_arm      : Factor w/ 328 levels &quot;&quot;,&quot;-0.00484&quot;,..: 1 1 1 1 1 1 1 1 1 1 ...
##  $ kurtosis_yaw_arm        : Factor w/ 395 levels &quot;&quot;,&quot;-0.01548&quot;,..: 1 1 1 1 1 1 1 1 1 1 ...
##  $ skewness_roll_arm       : Factor w/ 331 levels &quot;&quot;,&quot;-0.00051&quot;,..: 1 1 1 1 1 1 1 1 1 1 ...
##  $ skewness_pitch_arm      : Factor w/ 328 levels &quot;&quot;,&quot;-0.00184&quot;,..: 1 1 1 1 1 1 1 1 1 1 ...
##  $ skewness_yaw_arm        : Factor w/ 395 levels &quot;&quot;,&quot;-0.00311&quot;,..: 1 1 1 1 1 1 1 1 1 1 ...
##  $ max_roll_arm            : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ max_picth_arm           : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ max_yaw_arm             : int  NA NA NA NA NA NA NA NA NA NA ...
##  $ min_roll_arm            : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ min_pitch_arm           : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ min_yaw_arm             : int  NA NA NA NA NA NA NA NA NA NA ...
##  $ amplitude_roll_arm      : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ amplitude_pitch_arm     : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ amplitude_yaw_arm       : int  NA NA NA NA NA NA NA NA NA NA ...
##  $ roll_dumbbell           : num  13.1 13.1 12.9 13.4 13.4 ...
##  $ pitch_dumbbell          : num  -70.5 -70.6 -70.3 -70.4 -70.4 ...
##  $ yaw_dumbbell            : num  -84.9 -84.7 -85.1 -84.9 -84.9 ...
##  $ kurtosis_roll_dumbbell  : Factor w/ 398 levels &quot;&quot;,&quot;-0.0035&quot;,&quot;-0.0073&quot;,..: 1 1 1 1 1 1 1 1 1 1 ...
##  $ kurtosis_picth_dumbbell : Factor w/ 401 levels &quot;&quot;,&quot;-0.0163&quot;,&quot;-0.0233&quot;,..: 1 1 1 1 1 1 1 1 1 1 ...
##  $ kurtosis_yaw_dumbbell   : Factor w/ 2 levels &quot;&quot;,&quot;#DIV/0!&quot;: 1 1 1 1 1 1 1 1 1 1 ...
##  $ skewness_roll_dumbbell  : Factor w/ 401 levels &quot;&quot;,&quot;-0.0082&quot;,&quot;-0.0096&quot;,..: 1 1 1 1 1 1 1 1 1 1 ...
##  $ skewness_pitch_dumbbell : Factor w/ 402 levels &quot;&quot;,&quot;-0.0053&quot;,&quot;-0.0084&quot;,..: 1 1 1 1 1 1 1 1 1 1 ...
##  $ skewness_yaw_dumbbell   : Factor w/ 2 levels &quot;&quot;,&quot;#DIV/0!&quot;: 1 1 1 1 1 1 1 1 1 1 ...
##  $ max_roll_dumbbell       : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ max_picth_dumbbell      : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ max_yaw_dumbbell        : Factor w/ 73 levels &quot;&quot;,&quot;-0.1&quot;,&quot;-0.2&quot;,..: 1 1 1 1 1 1 1 1 1 1 ...
##  $ min_roll_dumbbell       : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ min_pitch_dumbbell      : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ min_yaw_dumbbell        : Factor w/ 73 levels &quot;&quot;,&quot;-0.1&quot;,&quot;-0.2&quot;,..: 1 1 1 1 1 1 1 1 1 1 ...
##  $ amplitude_roll_dumbbell : num  NA NA NA NA NA NA NA NA NA NA ...
##   [list output truncated]
</code></pre>

<pre><code class="r"># we see there are many NAs and &quot;#DIV/0!&quot; valeus generating a lot noise . Lets clean this up to create a tidy data set. Whatever we do to training we should also perform on testing

PML_training[PML_training==&quot;&quot;] &lt;- NA

PML_training[PML_training==&#39;&quot;#DIV/0!&quot;&#39;] &lt;- NA

PML_training &lt;- PML_training[,colSums(is.na(PML_training)) &lt; .5 * nrow(PML_training)]


# lets remove columns we do not need

PML_train_clean &lt;- PML_training[,c(-1:-7)]

dim(PML_train_clean)
</code></pre>

<pre><code>## [1] 19622    53
</code></pre>

<h2>Building a Model with Cross Validation</h2>

<p>Now lets build a machine learning algorithm to predict activity quality from activity monitors
Lets try two models: Trees and Random Forests. We will apply a cross validation when building our model.</p>

<h2>Regression Trees</h2>

<pre><code class="r">#### predict with trees

modFit &lt;- train(classe ~ .,method=&quot;rpart&quot;,data=PML_train_clean,  trControl = trainControl(method = &quot;cv&quot;))
</code></pre>

<pre><code>## Loading required package: rpart
</code></pre>

<pre><code class="r">print(modFit$finalModel)
</code></pre>

<pre><code>## n= 19622 
## 
## node), split, n, loss, yval, (yprob)
##       * denotes terminal node
## 
##  1) root 19622 14042 A (0.28 0.19 0.17 0.16 0.18)  
##    2) roll_belt&lt; 130.5 17977 12411 A (0.31 0.21 0.19 0.18 0.11)  
##      4) pitch_forearm&lt; -33.95 1578    10 A (0.99 0.0063 0 0 0) *
##      5) pitch_forearm&gt;=-33.95 16399 12401 A (0.24 0.23 0.21 0.2 0.12)  
##       10) magnet_dumbbell_y&lt; 439.5 13870  9953 A (0.28 0.18 0.24 0.19 0.11)  
##         20) roll_forearm&lt; 123.5 8643  5131 A (0.41 0.18 0.18 0.17 0.061) *
##         21) roll_forearm&gt;=123.5 5227  3500 C (0.077 0.18 0.33 0.23 0.18) *
##       11) magnet_dumbbell_y&gt;=439.5 2529  1243 B (0.032 0.51 0.043 0.22 0.19) *
##    3) roll_belt&gt;=130.5 1645    14 E (0.0085 0 0 0 0.99) *
</code></pre>

<pre><code class="r">print(modFit, digits =3)
</code></pre>

<pre><code>## CART 
## 
## 19622 samples
##    52 predictor
##     5 classes: &#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;D&#39;, &#39;E&#39; 
## 
## No pre-processing
## Resampling: Cross-Validated (10 fold) 
## 
## Summary of sample sizes: 17661, 17659, 17660, 17658, 17660, 17660, ... 
## 
## Resampling results across tuning parameters:
## 
##   cp      Accuracy  Kappa   Accuracy SD  Kappa SD
##   0.0357  0.504     0.3527  0.0166       0.0222  
##   0.0600  0.441     0.2502  0.0664       0.1114  
##   0.1152  0.323     0.0583  0.0405       0.0616  
## 
## Accuracy was used to select the optimal model using  the largest value.
## The final value used for the model was cp = 0.0357.
</code></pre>

<pre><code class="r">#Accuracy of 50 % is not so good. We should be able to do better

plot(modFit$finalModel, uniform=TRUE, main=&quot;Classification Tree&quot;)

text(modFit$finalModel, use.n=TRUE, all=TRUE, cex=.8)
</code></pre>

<p><img src="data:image/png;base64,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" alt="plot of chunk unnamed-chunk-4"/> </p>

<h2>Random Forests</h2>

<pre><code class="r"># Since 50% was not so great lets try to predict with random forests now (and also add cross validation with trcontrol and cv as the method)

model &lt;- train(classe ~ .,method=&quot;rf&quot;,data=PML_train_clean,  trControl = trainControl(method = &quot;cv&quot;))

print(model$finalModel)
</code></pre>

<pre><code>## 
## Call:
##  randomForest(x = x, y = y, mtry = param$mtry) 
##                Type of random forest: classification
##                      Number of trees: 500
## No. of variables tried at each split: 27
## 
##         OOB estimate of  error rate: 0.43%
## Confusion matrix:
##      A    B    C    D    E  class.error
## A 5576    3    0    0    1 0.0007168459
## B   18 3774    5    0    0 0.0060574137
## C    0   13 3400    9    0 0.0064289889
## D    0    0   23 3190    3 0.0080845771
## E    0    1    4    5 3597 0.0027723870
</code></pre>

<pre><code class="r">print(model, digits =3)
</code></pre>

<pre><code>## Random Forest 
## 
## 19622 samples
##    52 predictor
##     5 classes: &#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;D&#39;, &#39;E&#39; 
## 
## No pre-processing
## Resampling: Cross-Validated (10 fold) 
## 
## Summary of sample sizes: 17661, 17661, 17659, 17660, 17659, 17660, ... 
## 
## Resampling results across tuning parameters:
## 
##   mtry  Accuracy  Kappa  Accuracy SD  Kappa SD
##    2    0.995     0.994  0.00150      0.00189 
##   27    0.995     0.994  0.00125      0.00158 
##   52    0.990     0.988  0.00259      0.00327 
## 
## Accuracy was used to select the optimal model using  the largest value.
## The final value used for the model was mtry = 27.
</code></pre>

<h2>Random Forest continued (looking at variable importance and accuracy )</h2>

<p>Lets run randomForests again , but this time we will look at the importance of the variables, and how well the out of bag (aka out of sample error) was calculated. This should show us as the numbers are randomly permuted in the out of sample error estimation the overall mean decrease in the tree&#39;s accuracy is displayed (which shown in the figure below).    </p>

<pre><code class="r">model.rf &lt;- randomForest(classe ~ ., data=PML_train_clean, importance=TRUE,proximity=TRUE)

varImp &lt;- importance(model.rf)

varImpPlot(model.rf, type=1)
</code></pre>

<p><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAfgAAAH4CAMAAACR9g9NAAAAt1BMVEX9/v0AAAAAADkAAGUAOWUAOY8AZo8AZrU5AAA5ADk5AGU5OWU5OY85Zo85ZrU5j485j9plAABlADllAGVlOQBlOTllOY9lZgBlZjllZmVlZrVlj49ltbVltf2POQCPOTmPOWWPZgCPZo+PjzmPj2WPtY+P27WP29qP2/21ZgC1Zjm1tWW124+1/rW1/tq1/v2+vr7ajznaj2XatWXa24/a/rXa/tra/v39tWX924/9/rX9/tr9/v3MuUP9AAAAPXRSTlP///////////////////////////////////////////////////////////////////////////////8ACS+sXwAAAAlwSFlzAAALEgAACxIB0t1+/AAAGeZJREFUeJztnQ172zaWhYdxU6ceb+rWnW6yXTvtbHbGziR1tNutLVv//3ct8UESpEjwgvcConTP+1T5sEAG9TEI4ujy4C87oJK/HLoD4DBAeKVAeKVAeKVAeKVAeKVAeKVAeKVAeKVAeKVAeKVAeKVAeKVAeKVAeKVAeKVAeKVAeKVAeKVAeKVAeKVAeKVAeKVAeKVAeKVA+GSef3j9GPzl7CF4b/umenVXvksLgPDJxIS/r27Kd2gREH6Cp+rb2+rsYVNZKevfqqv695fbqvpPK7z5yk0n/Mvtq3eVJfipWDMQfoKnqqFW9t7+4dzq7rR1X7kKhK//+s1PEP7oeaoFr2fsm+cfXt1t39QTt/tDLfOm1nb7ptb35fbsIRD+fIdL/QnwVAtpVK2v4XdPVtRNdWP/YOZ4fz14dRdc6s1NHYQ/epzwrx8hvDJC4Scu9QYIf2qEwk/e3L1+NMI3M8IOwp8APeF7y7nv7XLu3v0AQHhwXEB4pUB4pUB4pUB4pUB4pUB4pUB4pUB4pUB4pUB4pUB4pUB4pUB4pUB4pUB4pUB4pUB4pUB4pUB4pUB4pUB4pUB4paxP+ArIEP82r1D4Q3fgRIDwSoHwSoHwSoHwSoHwSoHwSoHwSsko/H0YArC9eKj/Y5ytAcLLAOH10LPreMLX2m4vH7dvqurm5bb+83d3u6c2we/+vQ93NBmA24sv9nc2EH4p1S787vGEf7qq/3v+8c4M6M2VSfzaba6aN+9fP5pBfl9//VxwxH/d7b7iteBV+Zf7O0/4558fP9k05ufrh3rof/p4/vKhTWc2l/r7G/NjYd7Fpf7QSI74lw//+NlFPJ09PF9/uf588eW6Vdf8SNTC/1CZpD8If3gE5/jd5r0J6r3Z2Wv6L29fPnw8b9+rR3w98T+7nwQIvzKYwpvbOSOova2r3CzfcH++83P8k53tIfyaYAr/8uuDjff75id/Tx/cuNd39SbVr77Wv7I/HSbNOXuHARHuiH8r1hMiEF4GnvCbkR1WzKre3s8xehUBwssAr14pYsL3797y2LUGCC8DhD8CZmtil5wz/vaM8Nu//mRiuZ0Z3xM+i09vUCh833ITPGmEOeHfGFt2ZKGex6c3KPTqK/8SPS9T+FpPY809/3i3f6mX9+kNGPFyJ41AEN68Xj4MhM/j0xsUCr/GOT4y4jP49AaNwueAL/z4HJ/FpzdAeBkEhJ+4q8/g0xsgvAxw7pQiK3xmn94A4WUQET68zA9mc3ELD8LLIDXiIbwIORZuE/9S/O25Ysvr/3J3b9aTtbdy24t/r8IyHGnv9qSFz2LVTP9TEeaENzsnn3lrzlTWP73+481VUFsv792etGVb+VeBf4sr/E3n2jlNGzOvEV7au8WIl/unIswJ/6O1Zr3wl2acD4QX925PWvjjmeNr4WdHvKx3e9rCl4N7qT/vPFn79NzF54Hw0t4thJeBO+LfBZ6sv6vvCy/t3UJ4GQTm+LJAeBkyCZ/Pu4XwMuBDGqUUEb5/R2duAvfx3u6sxQvhZYDwB6bcyn3w78bfnn0+/mNVXT3VLzetO1f+m7/dbS9/6zz658CgN2//dONv/cPDvak/8PYD4e/rb9H5yQlf0Kvb/4cjzAl/Wy/T39ilug9EsSv2elHnHfvWo2+OMG9XrfDd4a2pH/H2bdrGiXn1WUqn83v1Rgrz8nf3z9cPxqNzXl7z0+A8en+Affu2G/Hd4c7Uj3r7m/rCgBEv+A9HSBHeBqIYwz4QvvXo/QGuOnNMeGfqx7x991nAiQl/tHN8q5wPRBmM+Naj9wdER7y565v29n2s0qkJfyjEhN/6QBQ/x3vjtvXomyPcHG+U3pz1hfdT/aS3by/0EF4KuUu9D0Spr9LftiPee/SBQf9ya1vVjb+/7gvvTP2ht98Kb6/+9e0/hJchxzpe7umJESC8DNLC1yN6zKFnePeDQyG8DPDqlQLhlQLhF3OoFbgMTOGdM2/Ty//oYlHqFVtYPu9cfBOb8ntgzjtc8Llch8txMM9NBqbwbtVu08uDWBTjv2zaUFvv4pv3Q3PeYQ9N6vDh/XX3KlgDvz6v3vt0Nr08CEnYL8zxhv3A298Fwedk4VMa50T1iPfOvE0vD2JRzMU9XLk5F39UeB98Ltbhgmie4/2It+nlwYg3b3WPUXkXf1x4e6hghwERkTm+TS/3c7wRvRPeu/gTwptDBTsMiPDv6r81Yv76EMaiuGt728i5+BPC2+BzuQ4DIvx1vB3Qy9PLUw+F8DJwS6+siT6WXj7jzzdvvku17yG8DHDulJI5A6e+JKTdtM8C4WXInIEj/9H8AYU/7oX7gLwZOPYrvkY+sPJj5j2zwxk5cqtuQOYMnKB+zlv5m/O4eT/b4YP52/0tOo/9lTkDx1fa+mJMXy5vj5wy72eFJ7aTByO+YzYDp7NqfemlW95FzHtmh3OCOb5lNgNnMOL9aI+a97wOAyKZM3AGtfXdH6fNe16HAZHMGTj+An/WWfnmSh8173kdBkSQgaMUZOAoBV69UhCFohQIT+Ok1vCGI8rAcRX4h4sROC3ljycDx1fgH8arPy2fnu/Vl8zA8RX4GPEyHE8Gjq/Axxwvw/Fk4PgK/BP7/h+M48nA8RX4EF6Go8nAaSrwIbwMR5SB4yrwIbwMx5OB4yvwIbwM8OqVUkh4nk0bAuFlgPDj/8qpLdv3KJGBw86oT+iwDKdn1O1RIAOHn1Hf63AJL/vI823ye/WkDBx+Rn1P+HiPZMCIl8jAYfjzI1FomONlKJGBw86oT+gwIFIgA4efUZ/QYUCkRAYOO6M+ocOAyMEzcFKB8DIcKgMnTuRQCC8DvHqlFBBeNgcHwstQQHjZj+fzCn/66/eG/F79ghycEYue2mEeChy7hgJefbBGJ+fgjDg3TYfh0R+LV79dkIMz4tw0wsd7xAMjvkHIq98m5uBEdivBHC9DAa9+m5yDM32hVzMgs1Morz4tB2f6Qg/hpSjg1Sfn4IxZ9NQOAyLw6pWyKq+ecgSElwFevVJyCS+ZftIDwssA4RWt3UOYwnfBN/XE3P56FoZb8mNvUjqcjiK3LoQfcLhtkur/tL8+ysfe9DsMf34FXr0V/zrIrd7tnuVjb/rCz/coDYz4MWaFb4NvGoM9Q+xNSocXgDl+BMIOFduL/oiXj71J6TAgwvx0zjnuLqn+d/vrg3zsTUqHARHmpb4Lvgnv6l/dhTd37NiblA4DIut27kY+A4DwMuQTXi72pgeEl2HdI34ECC+DmPCzXqsQEF4GxcLrXL83MJdzXaH8YB3G2D02jphYSh27BqbwXS1932vl7B4702F49Cvw6oPK2r1L/eLdY+NgxMsg4Ny1NfOh8IzdY+Ngjpchz4hn7R7L6jAgwhd+bI6PVs1n7TAgIiD82F09Z/fYOBBeBjh3SpEVPt+Wsi0QXgaMeKUUET4opmLn4UB4GQoLz/fv+MLrXr83MJ+dS9xbViAPhy2acseugfvQZOLesvw8HLZXr9yjl/Hqk/eW5efhYMTLICg8cW9ZZh4O5ngZxISn7S3Lz8OBaDKICe/t+Zm9Zfl5OBBeBrlLPWlvWX4eDoSXIcc6PmvtHYSXQVp4sb1lp46A8DLAq1cKolCUokl4LOAD1p2BM5Jbv1w7WHYhq87AGYszXu7VV/51eJ98Da9VZ+CMxRljxMuw6gycsdx6zPEyrDoDZyy3HtrJsOoMnP0LPYSXYs0ZOKO59RBeBjh3Sll1Bs7YoRBeBox4pRQur070Z0eA8DJoEB7r9xHK1tXvGfNfurecZcvt8MQRUH5I4br6iDH/fP3lmjD60716ePTyXn1yXX3MmN+QHqvDiJehcF191Jjfj6pO7/DoIZjj9ylcVx8Lp79/T5jiMXaFKFxXHzHmt5d/RvYSpnYYEClcV79nzLdvuWKOyd3DqR0GRFBXr5TD19UnevoQXgZ49UqB8Eo5beGxgp+EJ7zb/NW69Lb8ql7OdXfmeTLrU5SEZzcNT3i7+at36TdX9YrupquTy5RZn+LVV18F8+1P7MWssm02fzXG++Xjp4/n/cLYDJn1GPEycA0cu/mrdenNp2ufL8JP2LJk1mOOl4FbZfv+qimu393/8vblw8fWb8+UWQ8lZeA+NPndXVNcv3uq3CzfvJUnsx7Cy8AU3m7+6l16K/5Zd6XPk1kP4WXgjvj9zV8zA+Fl4Am/EYm7SQLCy3Dazh2YpIDw/Iz6EAgvQwHhZT+eTzJwsIyfhCm8q6K3lv0fQQD9U9VV0i/JqL8Zi0QgdXjYFMpPwBTeVdhZyz7YZ9bUUnYPRwQ1dsSMenu+qQ7T/ejKvw7ui6/xxfTqXU2tteybOGpTcdtbr2+TM+rbjwDGhI/3aNgUI34CZiKGq6K3ln1TX2k0rK/j3XJum5xR7z8CWNLhflvM8ZOIjHhr2Qcj3rwVfC6fnFFvz7esw4CIyBzfWvZ+Ljei94RPzKiPPVQD4WXg39V/a3T7tQugN7fs98FdfXpGvf8IYFGHARH+Ot6OXWHLPnI+CC8D9zFpe6M2ZtlzMurfRY6B8DLAq1dKCeHZ8SchEF6G0xUei/go+b36aO7NSCA9r8O9dlB+mgJefWIg/VyHqV70V9TUH9irTwyknxM+oR1G/DQFvPrEQHpeh4OGmONjFPDqEwPpeR0GRAp49YmB9LwOAyIFvPrp3JvRQHpehwGRdXr1ESC8DIfx6hm19xBeBnj1ShETvn+3LlpK3wPCy5BH+IxJd0ThsYqfgWngdP78YPuo1FJ6qQ4HraB8DKbwnT+/N+LTSunpHSZ50cioz+vVB27dUPjEUnq68ORWGPEx+MJ3NfM94RNL6aU63DbDHB+nyIinlNILdRgQ4Qs/M8dTS+mFOgyICAi/f1e/pJReqMOACJw7pcgKnzn/xgDhZcCIV0oey9Zg4qz38aXWyyuuIbwMJyk8FvHzZPHqXb29u4E3FTeBM+9r7Ael9rLCw7YjkMert1+rWuEDZ76psY+U2s90eN6HRvbNwbx6W3172434btXuauyjpfYzwtOaYMTPkM2rN8KOCO9q7GOl9rwOuzaY42c5wIg3d32RLWZ5HQZE8nj1fo63O4+e9YX3U/1kqT2zw4BIHq/eFN2ZCPtNVX1/3Rfe1dgPS+0hfGng3CkFXr1SMOKVUkh4Of8WwstwesJjEU+iRAbOcuPeWbopHYZtR6RIBs5i497sXjkY/XNePbJvSnj1pAwcjnG/2XvWBiNehjJ59YuN+/0Ya8zxMhTIwOEY9/fvhzF4UFWGIhk4i4377eWfw3gkCC9DiQycxca9uRwEP0CUDgMiyMBRyqry6imHQngZ4NUrpYjw4W06N8IcwstwasJjFU+EOccHxrtLuPHu/fbyt85/f+4C6vnZ9fEOw7ejwr25a413n3DjV/bbN3ZR3vnvzRHs7Pq4D4/smzJe/eA59+frB+/leZuu899b4bnZ9RjxMggK7xJunHvfCN/6780R7Ox6zPEyiAnvE24GI77135sj2Nn10FUGMeG3LuGmmeP9R3VBEI6DnV0P4WWQu9S7hBvv3jfCO/+9DagXyK6H8DLkWMcnr81TgPAySAvv3fshctn1EF4GePVKySd8psx6CC9DPuEzzfQzBg6W8UR4wtuC+kfr0ptqGbOcaypmcmXWRzsM444MT3hbUO9d+nodvqk1bZfjwXJdMrM+6tVX/rUCL3ztL2aVrSmot3+4Nmbtp4/nnf+2zZNZjxEvA9fA+cfPj96lN0+9fL7onnzZ5smsxxwvA/PmzhTUe5d+d//L25cPH9uP1Ld5MushrAxM4ZuCentbV7lZvnkrT2Y9hJeBKbwpqG9ceit+V06/zZNZD+Fl4I74cgX1HggvA0/4sYL6zDk4EF4GePVKySV8UFkj69lDeBnyCy/s2Y93GOv3VLg3d20xfT2nt782d/KGBZ59tMJ+tMNw7JJhWrY/+vop8zjzn+6h5mEp/RLPPlJ4OerVw6Mv7NVb8Zu6effrXin9Es9+M31XgBEvA1f4tpi+qYvfK6Vf4NnHKuwxx8vAvNR31ns74oel9OmefbTCHgLLILBDxXd3tgjj4nf768OwlD7ds49c6CG8FNxP59pi+vCu/tXd4OYuybOPV9hDeBng3CklY7FlsmdPOgLCy4ARr5RTi0IBRE5DeCzjk1lRBs4NKRphrMMw7tJZTwaOrdEndHjMd/6KjPqyXr1kBk5boz8j/MTXMOLTWE8Gjq/RX9RhzPHJrCcDx9boszsMiKwnA2dkN4oFHQZEVpOB42v0uR0GRFaUgUOr0YfwMqwnA+cdzdWH8DLAq1dKYcuWX2QP4WUoLDy/yH7UwMEyPpmyXv2SIvuBhT/SYRh3Cyjs1acX2Q8t/BFPvvKvg/vfx/Qq7NWnF9kPLXyMeBkKe/XpRfZDCx9zvAyFvfoFwTgDCx8Sy1DYq18QjDOw8CG8DIW9+gXBOAMLH8LLsCKvfupsfQsfwstweK9+gikLH8LLAK9eKaXLq9lAeBlOQnis49MpXVe/OPsm0mE4dwso7NUvz75pOwyv/hi9et9qQfZNK/z4lzDiEyldV784+ybWYczx6RT26pdn3xA7DIgcwKtfln1D7DAgUrqufnH2DbHDgMj6vfoBEF6GNXj1SUY+hJcBXr1S8seW89NPekB4GY5feCziF5E9rz4ae0Mx52c6DNtuGfnz6iOxN0TPpt/hoef8Ffk35b16K/5MXn0k9obo2fSFH/k7Rnw6+fPqI7E3JHN+rsOY4xeRP68+EnuTfqHH6JYif159JPYm/UIP4aXIn1c/HXtDM+fTOgyIwLlTykHy6jnbz0J4GTDilXKA8mpzK7iPN3Zn/V0IL8PRC49l/DJK19Wbt10Fjrm/Dw73jv7A2A+Ed5bvsMMw7hZSPK++/nrVCh+U1jeO/qSx/3z9xXhAA18eNfUH8eqT6+rt27fdiO8Od45+zNjf2CU/RrwM5TNwjLAjwjtHP2rs22gMzPEylK6rj414c9cXybO/f38+32FApHhevZ3jbTn2WV94P9VPGvvbyz/NZzoQXobSdfUvt7ZV3fj7677wztEfGvut8K7Y4xHCC4G6eqWsoa4+zuBQCC8DvHql5BWe586OAuFlOHbhsYxfCE94FyZvXXpbflUv58ydt2O5LU/vMIy7pfCEt2Hy3qXfXNWLtJugjm65LR/tcM9zrvzr8N73sb2YVbZNmLwx1i8fP3087wpnObZ8TPi9v2HEL4Fr4NgweevSm0/PPl98uZaw5ekdxhy/EG6V7furprh+d//L23omb5+F49jyyzsMiHAfmvzurimuryd0N8s3LLflGR0GRJjC2zB579Jb8c868Rbb8pwOAyLcEU/aD1YSCC8DT/iNrC1PAcLLAK9eKfmjUPjbyfaA8DLkF1740/mgw1jDM8iegSOwnexEh+HaccifgROs1RduJ9vvMHz6FXj1VvyZDJwtezvZvvC9P2HELyV/Bs6WvZ3sVIcxxzPIn4GzZW8nm9JhQCR/Bs6gvH7BdrIpHQZE8mfg+As8YzvZlA4DIqt07mKfAEB4GQ6SgTNzxHA72R4QXoZVjvgYEF4GCK8UCK8UCK+U4xMeyBD/Nq9P+AmSLgQn35h/XYTwR9kYwittDOGVNobwShtDeKWNIbzSxoqEB7JAeKVAeKVAeKVAeKVAeKVAeKVAeKVAeKVAeKUcgfBPlX3u+vmH6vX8ZvS+8aaqqjPCY/s2i5d2Zt+YdmbfinZm35jY55fbJlKK1Okp1i+8eRhnc26/65tzYuN+fnIEk95GO7NvTDyza0U881jmc7T10+tHcqenWL/wBv9cJi17w6ctks77V/N4GPHMtjHtzL4V7cy+MbHP3SPovCiS4xDeBDFcPoZP38Ub22e15wfQy4d/3t5Qz+wa087sW9HO7BsT+2y2+DSPLpK/HRMcg/DbN69cWjrl/9Q2Nk/jEkbQ5qrZAYlwZteYdmbfinZm35jYZ5MxUqtO/XZMcgzC2xQO+o9402p2zqxP+UIe8b4x7cy+VcKwJM/z/pwqRvzOhmDTJzXqN3Fjy8+vaGf2jWln9q0y9NnEyNjtH09/jvcXtZfbK8JtrG9sfos9g99iBjHtzLtuZ7z5M/tW9D7Xjal9dpFh5E5PsX7hzVijL1x94w3x8e1F63jCmTP22cfJnf46HmQBwisFwisFwisFwisFwisFwisFwisFwisFwisFwisFwisFwisFwisFwisFwisFwisFwisFwisFwitFo/Bmv9Pd7n7iAUW3cQ7x2bsAVpV7eVQK/92/Pe6e/zZRle73UEtW/imyieIKUSn8xbu73fZ9u11es/P15W/2N7erpnlSpS1kfnW3v1F28Pi2+c1vmxpszWf3XLx4sEeGm3JH99Iuhk7h/3Wz+5//dhtkhjtfB1tomq+5d91jFH/sbZRtnmWxT2S7JxtqLe9vduG223944esje5ty/29sL+1i6BT+89uXXz/X2u3tfN3uo/vy4a63bfb+Rtl+Tm++uKnlbLZK735tzxdsyh3dS7sYOoX//e//9x9m0O7tfN0KZR5P89tmu5209zbKNld8d1U3X3y5rYbbbvfOF2zKHd1Luxg6hX/49PHKX613vZ2vW6Hqa35v2+z9jbJ3/VZG0/ubiRHf25Q7upd2MZQK/+TuvfZ2vm7UsXf17l23k/bnvY2yzUOO5uW+uDGrgKfzcNvtL/UksGkvJN2m3A+xvbSLoVT4diQOdr62N2PNOt6/296i95v7C777onvM1c0P7Ybbdbvv/cTe25Sb9BxvbjQKf2hie2kXA8IXZ5Ow/3Y+ILxSILxSILxSILxSILxSILxSILxSILxSILxSILxSILxSILxSILxSILxSILxSILxS/h9fPOrDXG12ZwAAAABJRU5ErkJggg==" alt="plot of chunk unnamed-chunk-6"/> </p>

<h2>Results (cross validation, generalization/out of sample error)</h2>

<p>We concluded Random Forest is the right choice to constructed our Machine Learning Algorithm
to predict activity quality from the activity monitors with the test data. The accuracy in the regression trees was only 50% and jump up the 99.5% with Random Forests. Both models were built with a 10 fold cross validation. We expect our out of sample error (aka generalization error) to be .43% with Random Forests.</p>

<pre><code class="r">#now lets generate our results off our model and the test data set.
answers &lt;- predict(model,newdata=PML_testing)

#lets take a look at our results
summary(answers)
</code></pre>

<pre><code>## A B C D E 
## 7 8 1 1 3
</code></pre>

<pre><code class="r">##Now lets write out our answers into individual files for the submission
</code></pre>

<pre><code class="r">#go to my answers directory
setwd(&#39;C:\\coursera\\ML\\answers&#39;)

pml_write_files(answers)
####
</code></pre>

</body>

</html>

