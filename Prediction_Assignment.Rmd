---
title: "Prediction_Assignment_Writeup"
author: "Richard Green"
date: "Sunday, January 25, 2015"
output: html_document
---
Prediction_Assignment_Writeup
-----------------------------

Executive summary 
-----------------
Outlined below I used personal activity data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. These participants were asked to perform barbell lifts correctly and incorrectly in 5 different ways. I took this data and constructed a machine learning algorithm that allowed me to predict accurately the manner in which they exercised. Ultimately the random forest approach proved to be the best being able accurately predict all 20 entries in my test data set.

More information on this study can be found here: http://groupware.les.inf.puc-rio.br/har
Load libraries and results Function
-----------------------------------
Session info
```{r}
sessionInfo()
library(caret)
library(randomForest)
library(RCurl)
library(e1071)
library(rattle)
library(WGCNA)

pml_write_files = function(x){
  n = length(x)
  for(i in 1:n){
    filename = paste0("problem_id_",i,".txt")
    write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
  }
}

```
Setting a seed and loading in our data
```{r}

set.seed(1234)

PML_training <- read.csv(file="C:\\coursera\\ML\\pml-training.csv", header=T)

PML_testing <- read.csv(file="C:\\coursera\\ML\\pml-testing.csv", header=T)
```

Data Preprocessing and Cleaning
```{r}

#Now lets take a look at the data

str(PML_training)

# we see there are many NAs and "#DIV/0!" valeus generating a lot noise . Lets clean this up to create a tidy data set. Whatever we do to training we should also perform on testing

PML_training[PML_training==""] <- NA

PML_training[PML_training=='"#DIV/0!"'] <- NA

PML_training <- PML_training[,colSums(is.na(PML_training)) < .5 * nrow(PML_training)]


# lets remove columns we do not need

PML_train_clean <- PML_training[,c(-1:-7)]

dim(PML_train_clean)

```
Building a Model with Cross Validation
-------------------------------------
Now lets build a machine learning algorithm to predict activity quality from activity monitors
Lets try two models: Trees and Random Forests. We will apply a cross validation when building our model.

Regression Trees
----------------
```{r}
#### predict with trees

modFit <- train(classe ~ .,method="rpart",data=PML_train_clean,  trControl = trainControl(method = "cv"))


print(modFit$finalModel)

print(modFit, digits =3)

#Accuracy of 50 % is not so good. We should be able to do better

plot(modFit$finalModel, uniform=TRUE, main="Classification Tree")

text(modFit$finalModel, use.n=TRUE, all=TRUE, cex=.8)
```
Random Forests
--------------
```{r}
# Since 50% was not so great lets try to predict with random forests now (and also add cross validation with trcontrol and cv as the method)

model <- train(classe ~ .,method="rf",data=PML_train_clean,  trControl = trainControl(method = "cv"))

print(model$finalModel)

print(model, digits =3)
```
Random Forest continued (looking at variable importance and accuracy )
-----------------------------------------------------------------------
Lets run randomForests again , but this time we will look at the importance of the variables, and how well the out of bag (aka out of sample error) was calculated. This should show us as the numbers are randomly permuted in the out of sample error estimation the overall mean decrease in the tree's accuracy is displayed (which shown in the figure below).    

```{r}
model.rf <- randomForest(classe ~ ., data=PML_train_clean, importance=TRUE,proximity=TRUE)

varImp <- importance(model.rf)

varImpPlot(model.rf, type=1)

```
Results (cross validation, generalization/out of sample error)
-------------------
We concluded Random Forest is the right choice to constructed our Machine Learning Algorithm
to predict activity quality from the activity monitors with the test data. The accuracy in the regression trees was only 50% and jump up the 99.5% with Random Forests. Both models were built with a 10 fold cross validation. We expect our out of sample error (aka generalization error) to be .43% with Random Forests.

```{r}
#now lets generate our results off our model and the test data set.
answers <- predict(model,newdata=PML_testing)

#lets take a look at our results
summary(answers)

##Now lets write out our answers into individual files for the submission

```{r}
#go to my answers directory
setwd('C:\\coursera\\ML\\answers')

pml_write_files(answers)
####